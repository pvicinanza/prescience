{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Prescient Ideas using BERT: A Tutorial\n",
    "\n",
    "Author: Paul Vicinanza\n",
    "\n",
    "E-mail: pvicinan@stanford.edu\n",
    "\n",
    "The tutorial provides introductory code to:\n",
    "\n",
    "1. Finetune custom BERT models over a temporally split corpus\n",
    "2. Compute prescience using the finetuned BERT models\n",
    "3. Analyze prescience to understand what the model deems prescient\n",
    "\n",
    "#### A note:\n",
    "\n",
    "This tutorial is designed with social scientists with little computational background in mind. As such, the entire code is executed in jupyter notebook, uses pandas dataframes to store data, and is heavily commented for ease of implementation. \n",
    "\n",
    "Please check out an interesting use case on the shifting discursive meaning for the word **welfare** in US politics at the end of the notebook.\n",
    "\n",
    "#### Citation\n",
    "Paul Vicinanza, Amir Goldberg, Sameer B Srivastava, A deep-learning model of prescient ideas demonstrates that they emerge from the periphery, *PNAS Nexus*, Volume 2, Issue 1, March 2023, pgac275, https://doi.org/10.1093/pnasnexus/pgac275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies\n",
    "\n",
    "The deep learning architecture of this approach is built with hard work of the PyTorch and Huggingface transformers teams. To utilize GPUs for training and evalution (highly recommended) install PyTorch using [their website](https://pytorch.org/get-started/locally/) and cuda for GPU acceleration.\n",
    "\n",
    "Other packages needed for the tutorial\n",
    " * [transformers](https://huggingface.co/docs/transformers/installation) - For BERT models\n",
    " * [swifter](https://github.com/jmcarpenter2/swifter) - Automatic pandas dataframe parallelization\n",
    " * [nltk](https://www.nltk.org/install.html) - For sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import swifter\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForMaskedLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling  # In data/data_collator.py\n",
    ")\n",
    "tqdm.pandas()\n",
    "\n",
    "# Import custom functions \n",
    "from bert_finetune_utils import *\n",
    "from read_politics_helpers import *\n",
    "from prescience_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "For this tutorial, we will be using the bound and daily editions of the United States Congressional Record. This dataset contains speeches made on the House and Senate floor by U.S. politicians. Download and unzip here: https://stacks.stanford.edu/file/druid:md374tz9962/hein-bound.zip\n",
    "\n",
    "For this example, we'll be using speeches from the 87th congress (1961-1963) and the 107th congress (2001-2003)\n",
    "\n",
    "\n",
    "#### Citation\n",
    "\n",
    "Gentzkow, Matthew, Jesse M. Shapiro, and Matt Taddy. Congressional Record for the 43rd-114th Congresses: Parsed Speeches and Phrase Counts. Palo Alto, CA: Stanford Libraries [distributor], 2018-01-16. https://data.stanford.edu/congress_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7cbec76eaa444d8af9a4d1f5782075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dask Apply', max=56.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99421b737bf3444f84404861a40f6a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dask Apply', max=56.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\Paul\\Dropbox\\bert\\politics\\data\\speeches\"\n",
    "cong_87 = readCongress(os.path.join(data_path, 'speeches_087.txt'))\n",
    "cong_107 = readCongress(os.path.join(data_path, 'speeches_107.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examing the text data\n",
    "\n",
    "Using readCongress, we have read the speech data and split each speech act into separate sentences, which form the basic input for BERT. Now we are ready to finetune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070000001</td>\n",
       "      <td>The majority leader.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1070000001</td>\n",
       "      <td>Senator DASCHLE is recognized.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1070000002</td>\n",
       "      <td>Mr. President on behalf of the entire Senate b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1070000002</td>\n",
       "      <td>I welcome you back to the Senate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1070000002</td>\n",
       "      <td>This is a historic day.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speech_id                                             speech\n",
       "0  1070000001                               The majority leader.\n",
       "1  1070000001                     Senator DASCHLE is recognized.\n",
       "2  1070000002  Mr. President on behalf of the entire Senate b...\n",
       "3  1070000002                  I welcome you back to the Senate.\n",
       "4  1070000002                            This is a historic day."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_107.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Finetuning BERT\n",
    "\n",
    "For this finetuning example we'll use the 107th congress. This step is time intesive and not necessary to complete the tutorial.\n",
    "\n",
    "Links to already finetuned models of the 87th and 107th congress are available at the start of section 2: **Computing Sentence Perplexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cong_107\n",
    "model_name = 'bert_base_uncased_107th_congress'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking the BERT model\n",
    "\n",
    "We use the default BERT base uncased model, but this approach can use a custom BERT model or even taken a custom BERT vocabulary using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = 'bert-base-uncased'\n",
    "vocab = bert_model  # Path of vocabulary for BERT tokenizer - If using default set to bert_model\n",
    "model = BertForMaskedLM.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training data\n",
    "\n",
    "We convert the data into an iterable object and remove:\n",
    "\n",
    "1. Really short sentences (to short to be useful in computing prescience)\n",
    "2. Really long sentences (likely errors in the sentence parser) which slow down training \n",
    "\n",
    "We use the BertDataset object to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de9858b4fec4312b8d16198b709b162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2162754.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct data object for training\n",
    "data = BertDataset(df['speech'], tokenizer_vocab_path=vocab,\n",
    "                   min_doc_len=12, max_doc_len=102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "Now we're ready to finetune. Below are the hyperparameters I used to finetune BERT to the politics data. \n",
    "\n",
    "Note 1: I *do not* split into a train/test split and simply finetune for an extended amount of time (approximately 1 day's worth of training on a 2080ti and 200,000 steps). This may be necessary when finetuning over small datasets to prevent overfitting. \n",
    "\n",
    "Note 2: If memory constraints are not an issue, set gradient_accumulation_steps=1 and per_device_train_batch_size=64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish GPU usage to accelerate training\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./finetuned_models/{}'.format(model_name),\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=1000,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=20000,\n",
    "    save_total_limit=10,\n",
    "    do_train=True,\n",
    "    seed=102093,\n",
    "    fp16=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=data.tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1518877\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 23732\n",
      "  Number of trainable parameters = 109514298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23732' max='23732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23732/23732 1:25:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.183600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.997100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.904500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.884100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.858100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.825800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.830100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.819100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./finetuned_models/bert_base_uncased_107th_congress\\checkpoint-20000\n",
      "Configuration saved in ./finetuned_models/bert_base_uncased_107th_congress\\checkpoint-20000\\config.json\n",
      "Model weights saved in ./finetuned_models/bert_base_uncased_107th_congress\\checkpoint-20000\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23732, training_loss=1.951372237585657, metrics={'train_runtime': 5151.6321, 'train_samples_per_second': 294.834, 'train_steps_per_second': 4.607, 'total_flos': 4.89298898516256e+16, 'train_loss': 1.951372237585657, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Computing Sentence Perplexity\n",
    "\n",
    "The second step is to compute sentence perplexity using multiple models. Reset the notebook to clear memory and import all the packages again.\n",
    "\n",
    "Finetuned BERT models for the 87th and 107th congress are available at the following link. Please download and unzip:\n",
    "\n",
    "https://drive.google.com/file/d/1Yf4UDPWrfHZqqaEwTm0ALWe_QFhUH6vw/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import swifter\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Import custom functions\n",
    "from bert_finetune_utils import *\n",
    "from read_politics_helpers import readCongress, splitSents\n",
    "from prescience_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish GPU usage to accelerate training\n",
    "# If not GPU is avaiable a) use a GPU on the cloud it is much faster or b) remove this cell bock\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll compute sentence perplexity using speeches from the 87th congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f611dad84ad6416180bd28d87c533079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dask Apply', max=56.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = "Insert Your Own Data Path",
    "cong_87 = readCongress(os.path.join(data_path, 'speeches_087.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And the finetuned models of the 87th and 107th congresses\n",
    "\n",
    "Note: Provide the same path as the output directory from finetuning, _NOT_ the specific save state. The code automatically selects the last save state from finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'C:\\Users\\Paul\\Dropbox\\bert\\politics\\example\\finetuned_models'\n",
    "models = [os.path.join(model_path, 'bert_base_uncased_87th_congress'),\n",
    "          os.path.join(model_path, 'bert_base_uncased_107th_congress')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The workhorse function is computePerplexitiesForPrescience\n",
    "\n",
    "View it's docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computePerplexitiesForPrescience?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purposes we'll be setting compute_sent_perp to false. This returns word-level perplexities instead of sentence-level perplexities - useful for exploring _what_ words contribute to prescience but is significantly more memory intensive.\n",
    "\n",
    "#### Note:\n",
    "Sentences are sorted by length (shortest to longest) to speed up computation. As a result, the initial tdqm time to completion is an underestimate (approximately twice as long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences using bert-base-uncased vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaeb316f3714a7d85178f4fc6371f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dask Apply', max=56.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tComputing perplexity for model bert_base_uncased_87th_congress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\envs\\xlnet_cuda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdea454031f47728b83f927e11b6146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch Size: 80', max=15310.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tComputing perplexity for model bert_base_uncased_107th_congress\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bb550e311a4022b97637768baf0b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch Size: 80', max=15310.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cong_87 = computePerplexitiesForPrescience(df=cong_87, text_col='speech',\n",
    "                                           model_names=models,\n",
    "                                           min_doc_length=17,\n",
    "                                           compute_sent_perp=False,\n",
    "                                           batch_size=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Prescience\n",
    "\n",
    "Great! Now that we've computed perplexities was can calcuate sentence-level and word-level prescience (the percentage reduction in perplexity). Let's start by examining at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>speech</th>\n",
       "      <th>sentence_encoded</th>\n",
       "      <th>len</th>\n",
       "      <th>perp_87</th>\n",
       "      <th>perp_107</th>\n",
       "      <th>perp_87_sentence</th>\n",
       "      <th>perp_107_sentence</th>\n",
       "      <th>prescience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870142234</td>\n",
       "      <td>These should all be resolved into one uniform ...</td>\n",
       "      <td>[101, 2122, 2323, 2035, 2022, 10395, 2046, 202...</td>\n",
       "      <td>19</td>\n",
       "      <td>[116382800.0, 1.0000936, 1.0000842, 1.0000198,...</td>\n",
       "      <td>[41355812.0, 1.0001391, 1.0001212, 1.0001454, ...</td>\n",
       "      <td>3.484322</td>\n",
       "      <td>1.056374</td>\n",
       "      <td>0.696821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>870175799</td>\n",
       "      <td>I could go on and show you graphs and diagrams...</td>\n",
       "      <td>[101, 1045, 2071, 2175, 2006, 1998, 2265, 2017...</td>\n",
       "      <td>19</td>\n",
       "      <td>[199467180.0, 1.0000932, 1.0004811, 1.0008867,...</td>\n",
       "      <td>[683502600.0, 1.0000639, 1.0010598, 1.0002803,...</td>\n",
       "      <td>3.464970</td>\n",
       "      <td>1.094587</td>\n",
       "      <td>0.684099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>870245738</td>\n",
       "      <td>Bucks career the Baltimore Sun described him a...</td>\n",
       "      <td>[101, 14189, 2476, 1996, 6222, 3103, 2649, 203...</td>\n",
       "      <td>18</td>\n",
       "      <td>[88162730.0, 230986.34, 1376.7389, 1.0145264, ...</td>\n",
       "      <td>[304884700.0, 1406.035, 2.2170944, 1.0010508, ...</td>\n",
       "      <td>4.703766</td>\n",
       "      <td>1.572839</td>\n",
       "      <td>0.665621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>870173965</td>\n",
       "      <td>* * * He was for a time donsidered prime Speak...</td>\n",
       "      <td>[101, 1008, 1008, 1008, 2002, 2001, 2005, 1037...</td>\n",
       "      <td>15</td>\n",
       "      <td>[315509200.0, 1.0001428, 1.0003302, 1.0007789,...</td>\n",
       "      <td>[174935360.0, 1.0000088, 1.0000067, 1.0001736,...</td>\n",
       "      <td>5.610222</td>\n",
       "      <td>1.879559</td>\n",
       "      <td>0.664976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>870208695</td>\n",
       "      <td>But the administration was going to solve the ...</td>\n",
       "      <td>[101, 2021, 1996, 3447, 2001, 2183, 2000, 9611...</td>\n",
       "      <td>19</td>\n",
       "      <td>[1718656400.0, 1.0005918, 1.0000684, 1.0022911...</td>\n",
       "      <td>[373450660.0, 1.0000672, 1.0002993, 1.0013235,...</td>\n",
       "      <td>3.457965</td>\n",
       "      <td>1.168118</td>\n",
       "      <td>0.662195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speech_id                                             speech  \\\n",
       "0  870142234  These should all be resolved into one uniform ...   \n",
       "1  870175799  I could go on and show you graphs and diagrams...   \n",
       "2  870245738  Bucks career the Baltimore Sun described him a...   \n",
       "3  870173965  * * * He was for a time donsidered prime Speak...   \n",
       "4  870208695  But the administration was going to solve the ...   \n",
       "\n",
       "                                    sentence_encoded  len  \\\n",
       "0  [101, 2122, 2323, 2035, 2022, 10395, 2046, 202...   19   \n",
       "1  [101, 1045, 2071, 2175, 2006, 1998, 2265, 2017...   19   \n",
       "2  [101, 14189, 2476, 1996, 6222, 3103, 2649, 203...   18   \n",
       "3  [101, 1008, 1008, 1008, 2002, 2001, 2005, 1037...   15   \n",
       "4  [101, 2021, 1996, 3447, 2001, 2183, 2000, 9611...   19   \n",
       "\n",
       "                                             perp_87  \\\n",
       "0  [116382800.0, 1.0000936, 1.0000842, 1.0000198,...   \n",
       "1  [199467180.0, 1.0000932, 1.0004811, 1.0008867,...   \n",
       "2  [88162730.0, 230986.34, 1376.7389, 1.0145264, ...   \n",
       "3  [315509200.0, 1.0001428, 1.0003302, 1.0007789,...   \n",
       "4  [1718656400.0, 1.0005918, 1.0000684, 1.0022911...   \n",
       "\n",
       "                                            perp_107  perp_87_sentence  \\\n",
       "0  [41355812.0, 1.0001391, 1.0001212, 1.0001454, ...          3.484322   \n",
       "1  [683502600.0, 1.0000639, 1.0010598, 1.0002803,...          3.464970   \n",
       "2  [304884700.0, 1406.035, 2.2170944, 1.0010508, ...          4.703766   \n",
       "3  [174935360.0, 1.0000088, 1.0000067, 1.0001736,...          5.610222   \n",
       "4  [373450660.0, 1.0000672, 1.0002993, 1.0013235,...          3.457965   \n",
       "\n",
       "   perp_107_sentence  prescience  \n",
       "0           1.056374    0.696821  \n",
       "1           1.094587    0.684099  \n",
       "2           1.572839    0.665621  \n",
       "3           1.879559    0.664976  \n",
       "4           1.168118    0.662195  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_87 = (cong_87.rename(columns = {'perp_bert_base_uncased_87th_congress' : 'perp_87',\n",
    "                                    'perp_bert_base_uncased_107th_congress' : 'perp_107'})\n",
    "                .drop_duplicates(subset='speech'))\n",
    "cong_87.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value in the perp column indicates the inverse probability that the model correctly estimates the masked token. A value of, or very close to 1, indicates that the BERT model estimated the token with high accuracy. The first token of every sentence is 101 (the '[CLS]' token) and the last token of every sentence is 102 (the '[SEP]' token). \n",
    "\n",
    "Let's begin by computing sentence-level prescience. This would be done automatically if compute_sent_perp was set to True.\n",
    "\n",
    "Note: sentencePerplexity function ignores the [CLS] and [SEP] tokens by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd10ff5439974cc9b870a515cafe7a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1134959.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b529dc7c8ff4f9d9595b18ae2d26929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1134959.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>speech</th>\n",
       "      <th>sentence_encoded</th>\n",
       "      <th>len</th>\n",
       "      <th>perp_87</th>\n",
       "      <th>perp_107</th>\n",
       "      <th>perp_87_sentence</th>\n",
       "      <th>perp_107_sentence</th>\n",
       "      <th>prescience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870142234</td>\n",
       "      <td>These should all be resolved into one uniform ...</td>\n",
       "      <td>[101, 2122, 2323, 2035, 2022, 10395, 2046, 202...</td>\n",
       "      <td>19</td>\n",
       "      <td>[116382800.0, 1.0000936, 1.0000842, 1.0000198,...</td>\n",
       "      <td>[41355812.0, 1.0001391, 1.0001212, 1.0001454, ...</td>\n",
       "      <td>3.484322</td>\n",
       "      <td>1.056374</td>\n",
       "      <td>0.696821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>870175799</td>\n",
       "      <td>I could go on and show you graphs and diagrams...</td>\n",
       "      <td>[101, 1045, 2071, 2175, 2006, 1998, 2265, 2017...</td>\n",
       "      <td>19</td>\n",
       "      <td>[199467180.0, 1.0000932, 1.0004811, 1.0008867,...</td>\n",
       "      <td>[683502600.0, 1.0000639, 1.0010598, 1.0002803,...</td>\n",
       "      <td>3.464970</td>\n",
       "      <td>1.094587</td>\n",
       "      <td>0.684099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speech_id                                             speech  \\\n",
       "0  870142234  These should all be resolved into one uniform ...   \n",
       "1  870175799  I could go on and show you graphs and diagrams...   \n",
       "\n",
       "                                    sentence_encoded  len  \\\n",
       "0  [101, 2122, 2323, 2035, 2022, 10395, 2046, 202...   19   \n",
       "1  [101, 1045, 2071, 2175, 2006, 1998, 2265, 2017...   19   \n",
       "\n",
       "                                             perp_87  \\\n",
       "0  [116382800.0, 1.0000936, 1.0000842, 1.0000198,...   \n",
       "1  [199467180.0, 1.0000932, 1.0004811, 1.0008867,...   \n",
       "\n",
       "                                            perp_107  perp_87_sentence  \\\n",
       "0  [41355812.0, 1.0001391, 1.0001212, 1.0001454, ...          3.484322   \n",
       "1  [683502600.0, 1.0000639, 1.0010598, 1.0002803,...          3.464970   \n",
       "\n",
       "   perp_107_sentence  prescience  \n",
       "0           1.056374    0.696821  \n",
       "1           1.094587    0.684099  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_87['perp_87_sentence'] = cong_87['perp_87'].progress_apply(sentencePerplexity)\n",
    "cong_87['perp_107_sentence'] = cong_87['perp_107'].progress_apply(sentencePerplexity)\n",
    "cong_87['prescience'] = percentDiffVec(cong_87['perp_87_sentence'], cong_87['perp_107_sentence'])\n",
    "cong_87.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prescience distribution\n",
    "\n",
    "The model trained on text from the 87th congress should, on average, outperform the model trained on the 107th congress, Looking at the distribution, we see that approximately 75% of sentences are better predicted by the 87th model. Most sentences have a prescience value very close to 0, indicating they are equally well-predicted by both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1134959.000\n",
       "mean          -0.060\n",
       "std            0.189\n",
       "min          -12.191\n",
       "1%            -0.837\n",
       "10%           -0.190\n",
       "25%           -0.041\n",
       "50%           -0.004\n",
       "75%           -0.000\n",
       "90%            0.006\n",
       "99%            0.151\n",
       "max            0.697\n",
       "Name: prescience, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_87['prescience'].describe(percentiles=[0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2731aec5730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot([i for i in cong_87['prescience'] if i >-.1 and i <=0.1], kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining prescient sentences\n",
    "\n",
    "Let's examine some highly prescient sentences and see what words drive their prescience. Let's look at the most prescient sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These should all be resolved into one uniform basic policy and Salmon Unlimited is working toward this end.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by prescient sentences\n",
    "cong_87 = cong_87.sort_values(by='prescience', ascending=False).reset_index(drop=True)\n",
    "cong_87.iloc[0]['speech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's driving this relationship? One strength of this methodological approach is that we can examine it word by word. To do this we first need to declare the tokenizer to convert the token indices back to English tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare BERT tokenizer\n",
    "tokenizer = declareTokenizer(vocab_path='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceToDataFrame(df, tokenizer, row,\n",
    "                        token_ind_col='sentence_encoded',\n",
    "                        early_perp_col='perp_87',\n",
    "                        late_perp_col='perp_107'):\n",
    "    '''\n",
    "    Converts a word-tokenized row into a separate dataframe\n",
    "    '''\n",
    "    \n",
    "    df = (pd.DataFrame(df.loc[row, [token_ind_col, early_perp_col, late_perp_col]].tolist()).T\n",
    "            .iloc[1:-1]\n",
    "            .round(4))\n",
    "    df.columns = ['token', 'early_perp', 'late_perp']\n",
    "    df['token'] = tokenizer.convert_ids_to_tokens(df['token'])\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>early_perp</th>\n",
       "      <th>late_perp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resolved</td>\n",
       "      <td>1.0026</td>\n",
       "      <td>1.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>into</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one</td>\n",
       "      <td>1.0026</td>\n",
       "      <td>1.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uniform</td>\n",
       "      <td>1.1520</td>\n",
       "      <td>1.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>basic</td>\n",
       "      <td>1.0026</td>\n",
       "      <td>1.0675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>policy</td>\n",
       "      <td>1.0009</td>\n",
       "      <td>1.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>salmon</td>\n",
       "      <td>99863.9766</td>\n",
       "      <td>1.3627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unlimited</td>\n",
       "      <td>165254.1250</td>\n",
       "      <td>1.5436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is</td>\n",
       "      <td>1.0348</td>\n",
       "      <td>1.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>working</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>toward</td>\n",
       "      <td>1.0013</td>\n",
       "      <td>1.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>this</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>end</td>\n",
       "      <td>1.0006</td>\n",
       "      <td>1.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>1.0031</td>\n",
       "      <td>1.0146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token   early_perp  late_perp\n",
       "1       these       1.0001     1.0001\n",
       "2      should       1.0001     1.0001\n",
       "3         all       1.0000     1.0001\n",
       "4          be       1.0000     1.0001\n",
       "5    resolved       1.0026     1.0034\n",
       "6        into       1.0001     1.0005\n",
       "7         one       1.0026     1.0001\n",
       "8     uniform       1.1520     1.2256\n",
       "9       basic       1.0026     1.0675\n",
       "10     policy       1.0009     1.0066\n",
       "11        and       1.0001     1.0000\n",
       "12     salmon   99863.9766     1.3627\n",
       "13  unlimited  165254.1250     1.5436\n",
       "14         is       1.0348     1.0004\n",
       "15    working       1.0004     1.0007\n",
       "16     toward       1.0013     1.0019\n",
       "17       this       1.0004     1.0004\n",
       "18        end       1.0006     1.0007\n",
       "19          .       1.0031     1.0146"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceToDataFrame(cong_87, tokenizer, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prescience in this sentence is driven by the term \"Salmon Unlimited.\"\n",
    "\n",
    "Salmon Unlimited is a non-profit organization devoted to protecting fishing stocks in the Great Lakes region of the United States. They only gained significant size and political influence in the 1970s, thus the model deems a discussion of this group as prescient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note of caution\n",
    "\n",
    "This measure can be noisy at the individual sentence level and not always interpretable. Take the 2rd most prescient sentence: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could go on and show you graphs and diagrams show you the massive effects of this credit.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>early_perp</th>\n",
       "      <th>late_perp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>could</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>1.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go</td>\n",
       "      <td>1.0009</td>\n",
       "      <td>1.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>1.0022</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>show</td>\n",
       "      <td>1.0071</td>\n",
       "      <td>1.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>you</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>graphs</td>\n",
       "      <td>39156.2930</td>\n",
       "      <td>1.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>diagrams</td>\n",
       "      <td>264667.0625</td>\n",
       "      <td>3.5563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>show</td>\n",
       "      <td>1.0249</td>\n",
       "      <td>1.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>you</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>massive</td>\n",
       "      <td>1.1756</td>\n",
       "      <td>1.0972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>effects</td>\n",
       "      <td>1.0315</td>\n",
       "      <td>1.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>of</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>this</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>credit</td>\n",
       "      <td>1.3749</td>\n",
       "      <td>1.3582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>1.0022</td>\n",
       "      <td>1.0030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token   early_perp  late_perp\n",
       "1          i       1.0001     1.0001\n",
       "2      could       1.0005     1.0011\n",
       "3         go       1.0009     1.0003\n",
       "4         on       1.0001     1.0000\n",
       "5        and       1.0022     1.0000\n",
       "6       show       1.0071     1.0042\n",
       "7        you       1.0001     1.0001\n",
       "8     graphs   39156.2930     1.0033\n",
       "9        and       1.0001     1.0000\n",
       "10  diagrams  264667.0625     3.5563\n",
       "11      show       1.0249     1.0101\n",
       "12       you       1.0000     1.0002\n",
       "13       the       1.0007     1.0000\n",
       "14   massive       1.1756     1.0972\n",
       "15   effects       1.0315     1.0271\n",
       "16        of       1.0000     1.0000\n",
       "17      this       1.0000     1.0003\n",
       "18    credit       1.3749     1.3582\n",
       "19         .       1.0022     1.0030"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 1\n",
    "print(cong_87.loc[ind, 'speech'])\n",
    "sentenceToDataFrame(cong_87, tokenizer, ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model deems a discussion using graphs and diagrams as highly prescient. Perhaps this is because figures and data become more heavily incorporated into the policy making process but it is impossible to say. To smooth out noise, it is best to aggregate these prescience calculations across many sentences when doing statistical inference. In the paper, we set a minimum sentence count of 100 sentences per politican-term for inclusion in regression analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interest in a particular word\n",
    "\n",
    "Sometimes, we might have interest in how a particular word is used. \n",
    "\n",
    "Let's examine at the term **welfare**. In the early 1960s (the 87th congress), welfare was still associated with Great Depression era policies which benefited white Americans. In the mid 60s, following the civil rights movement, welfare became a racialized issue and discourse began to focus on people exploiting the system. This rhetoric cumulated in Clinton's 1996 welfare reform act which limited payments to states and added work requirements for welfare.\n",
    "\n",
    "Soss, Joe and Fording, Richard C. (2003). Schram, Sanford F. (ed.). _Race and the politics of welfare reform_. Ann Arbor, Mich.: Univ. of Michigan Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this pattern empirical, we use the function wordPrescienceInContext. This function filters the corpus for a particular word and returns it's word-level prescience in the context of the sentence (average_word_prescience).\n",
    "\n",
    "Note: Multi-word phrases are not currently supported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e54c526e264c0c9fa469f2d11b6e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Filtering sentences for welfare', max=1134959.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6528 sentences found using the term welfare\n"
     ]
    }
   ],
   "source": [
    "search_term = 'welfare'\n",
    "word_df = wordPrescienceInContext(df=cong_87,\n",
    "                       word=search_term,\n",
    "                       m1_col='perp_87',\n",
    "                       m2_col='perp_107',\n",
    "                       sent_col='sentence_encoded',\n",
    "                       tokenizer=tokenizer)\n",
    "print(f'{word_df.shape[0]} sentences found using the term {search_term}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the most prescient usages in the 87th Congress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level prescience: 0.967\n",
      "Sentence-level prescience: 0.129\n",
      "Are we getting real facts on how many people have illegitimate children how many people were feeding on welfare that have illegitimate children?\n",
      "\n",
      "Word-level prescience: 0.925\n",
      "Sentence-level prescience: 0.143\n",
      "Dont you think that these fellows collecting welfare is a lot of these people that could do some light work and make this a better city to live in like clean the streets.\n",
      "\n",
      "Word-level prescience: 0.911\n",
      "Sentence-level prescience: 0.09\n",
      "\"Carrying his war against welfare * * *\" This is an untrue presentation.\n",
      "\n",
      "Word-level prescience: 0.906\n",
      "Sentence-level prescience: 0.116\n",
      "You have to go to welfare you sign up once you never have to sign up any more.\n",
      "\n",
      "Word-level prescience: 0.731\n",
      "Sentence-level prescience: -0.549\n",
      "Carrying his war against welfare far beyond the tiny boundaries of his city the Newburgh story has struck a responsive chord nationally.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in range(0,5):\n",
    "    word_pres = word_df.loc[ind, 'average_word_prescience'].round(3)\n",
    "    sentence_pres = word_df.loc[ind, 'prescience'].round(3)\n",
    "    print(f'Word-level prescience: {word_pres}')\n",
    "    print(f'Sentence-level prescience: {sentence_pres}')\n",
    "    print(word_df.loc[ind, 'speech'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Very*** clear anti-welfare rhetoric. Politicans who spoke of welfare in the same breath as \"illegitimate children,\" \"work,\" and \"war against welfare\" did so presciently.\n",
    "\n",
    "What about the least prescient usages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level prescience: -3012.754\n",
      "Sentence-level prescience: -0.221\n",
      "I include the following sermon delivered by the Reverend Dr. Thomas J. McMahon national secretary of the Catholic Near East Welfare Association on the occasion of the dedication of the Church of Our Lady of Lebanon of the Maronite Rite of Brooklyn.\n",
      "\n",
      "Word-level prescience: -3651.281\n",
      "Sentence-level prescience: -0.271\n",
      "The former Secretary of Agriculture charged with watching over the farmers welfare from Maine to California actually spent as much time traveling abroad in his latter term as John Foster Dulles.\n",
      "\n",
      "Word-level prescience: -3937.221\n",
      "Sentence-level prescience: -0.157\n",
      "Each of the Coast Guard installations which I visited was severely damaged and the personnel had great difficulty in continuing in service and yet they were able to meet every call which was made by the Office of Civil Defense and municipal agencies in the saving of lives and protecting the welfare to the greatest extent possible through the storm period.\n",
      "\n",
      "Word-level prescience: -8793.258\n",
      "Sentence-level prescience: -0.548\n",
      "Education and Welfare of drug information in the Senate bill as well as information on patents in the Senate bill.\n",
      "\n",
      "Word-level prescience: -9198.496\n",
      "Sentence-level prescience: -0.753\n",
      "How many so many people pulled out as soon as the welfare took an investigation?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in range(6523,6528):\n",
    "    word_pres = word_df.loc[ind, 'average_word_prescience'].round(3)\n",
    "    sentence_pres = word_df.loc[ind, 'prescience'].round(3)\n",
    "    print(f'Word-level prescience: {word_pres}')\n",
    "    print(f'Sentence-level prescience: {sentence_pres}')\n",
    "    print(word_df.loc[ind, 'speech'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These uses of \"welfare\" are very different. They either discuss the protection the welfare or people/farmers or in a proper noun such as \"Education or Welfare\" or \"the Catholic Near East Welfare Association\" which are no longer used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tutorial demonstrates how to \n",
    "1. Finetune BERT models\n",
    "2. Compute prescience using the finetuned BERT models\n",
    "3. Analyze prescience at the level of individual sentences and words\n",
    "\n",
    "For questions, comments, and suggestions please reach out to me at pvicinan@stanford.edu!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
