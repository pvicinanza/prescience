{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating prescient ideas using BERT: A Tutorial\n",
    "\n",
    "Author: Paul Vicinanza\n",
    "\n",
    "E-mail: pvicinanza@gmail.com\n",
    "\n",
    "The tutorial provides introductory code to:\n",
    "\n",
    "1. Finetune custom BERT models over a temporally split corpus\n",
    "2. Compute prescience using the finetuned BERT models\n",
    "3. Analyze prescience to understand what the model deems prescient\n",
    "\n",
    "#### A note\n",
    "\n",
    "This tutorial is designed with social scientists with little computational background in mind. As such, the entire code is executed in jupyter notebook and is heavily commented for ease of implementation.\n",
    "\n",
    "#### Citation\n",
    "Paul Vicinanza, Amir Goldberg, Sameer B Srivastava, A deep-learning model of prescient ideas demonstrates that they emerge from the periphery, *PNAS Nexus*, Volume 2, Issue 1, Janurary 2023, pgac275, https://doi-org.stanford.idm.oclc.org/10.1093/pnasnexus/pgac275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import swifter\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Import custom functions \n",
    "from bert_finetune_utils import *\n",
    "from read_politics_helpers import readCongress, splitSents\n",
    "from prescience_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "For this tutorial, we will be using the bound and daily editions of the United States Congressional Record avaiable. This dataset contains speeches made on the House and Senate floor by U.S. Federal Politicians. Download and unzip here: https://stacks.stanford.edu/file/druid:md374tz9962/hein-bound.zip\n",
    "\n",
    "For this example, we'll be using speeches from the 87th congress (1961-1963) and the 109th congress (2005-2007)\n",
    "\n",
    "\n",
    "#### Citation\n",
    "\n",
    "Gentzkow, Matthew, Jesse M. Shapiro, and Matt Taddy. Congressional Record for the 43rd-114th Congresses: Parsed Speeches and Phrase Counts. Palo Alto, CA: Stanford Libraries [distributor], 2018-01-16. https://data.stanford.edu/congress_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCongress(file):\n",
    "    '''\n",
    "    Read in and progress congressional data\n",
    "    @param file (str) - File of congressional speeches to process\n",
    "\n",
    "    @return df (DataFrame) - Dataframe holding political speeches\n",
    "\n",
    "    @dependencies splitSents\n",
    "    ''' \n",
    "    df = pd.read_csv(file, sep='\\n', encoding='latin-1')\n",
    "    df = [x[0].split('|')[:2] for x in df.values]   # Split on | - text after second | is dropped - extremely rare and inconsequential \n",
    "    df = pd.DataFrame(df, columns=['speech_id', 'speech'])\n",
    "\n",
    "    # Split dataframe on sentences\n",
    "    df = df[df['speech'] != ''] # Drop empty strings\n",
    "    df['speech'] = df['speech'].swifter.allow_dask_on_strings().apply(lambda x : splitSents(x))\n",
    "\n",
    "    # Expand dataframe so that each sentence is a unique row\n",
    "    df = expandDF(df, 'speech')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"INSERT PATH TO SAVED DATA\"\n",
    "cong_87 = readCongress(os.path.join(data_path, 'speeches_087.txt'))\n",
    "cong_107 = readCongress(os.path.join(data_path, 'speeches_107.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examing the text data\n",
    "\n",
    "Using readCongress, we have read the speech data and split each speech act into separate sentences, which form the basic input for BERT. Now we are ready to finetune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_109.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Finetuning BERT\n",
    "\n",
    "For this finetuning example we'll use the 107th congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cong_107\n",
    "model_name = 'bert_base_uncased_107th_congress'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking the BERT model\n",
    "\n",
    "We use the default BERT base uncased model, but this approach can use a custom BERT model or even taken a custom BERT vocabulary using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = 'bert-base-uncased'\n",
    "vocab = bert_model  # Path of vocabulary for BERT tokenizer - If using default set to bert_model\n",
    "model = BertForMaskedLM.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training data\n",
    "\n",
    "We convert the data into an iterable object and remove:\n",
    "\n",
    "1. Really short sentences (to short to be useful in computing prescience)\n",
    "2. Really long sentences (likely errors in the sentence parser) which slow down training \n",
    "\n",
    "We use the BertDataset object to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct data object for training\n",
    "data = BertDataset(df['speech'], tokenizer_vocab_path=vocab,\n",
    "                   min_doc_len=12, max_doc_len=102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "Now we're ready to finetune. Below are the hyperparameters I used when finetuning BERT to the politics data. \n",
    "\n",
    "Note that I *do not* split into a train/test split and simply finetune for an extended amount of time (approximately 1 day's worth of training on a 2080ti). This may be necessary when finetuning over small datasets to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish GPU usage to accelerate training\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./output/{}'.format(model_name),\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=8,\n",
    "    logging_steps=1000,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=30000,\n",
    "    save_total_limit=10,\n",
    "    do_train=True,\n",
    "    seed=102093,\n",
    "    fp16=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=data.tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Computing Sentence Perplexity\n",
    "\n",
    "The second step is to compute sentence perplexity using multiple models. Reset the notebook to clear memory and import all the packages again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import swifter\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Import custom functions \n",
    "from bert_finetune_utils import *\n",
    "from read_politics_helpers import readCongress, splitSents\n",
    "from prescience_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish GPU usage to accelerate training\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll compute sentence perplexity using speeches from the 87th congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\Paul\\Dropbox\\bert\\politics\\data\\speeches'\n",
    "cong_87 = readCongress(os.path.join(data_path, 'speeches_087.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And the finetuned models of the 87th and 107th congresses\n",
    "\n",
    "Note: Provide the same path as the output directory from finetuning, _NOT_ the specific save state. The code automatically selects the last save state from finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'C:\\Users\\Paul\\Dropbox\\bert\\politics\\example\\output'\n",
    "models = [os.path.join(model_path, 'bert_base_uncased_87th_congress'),\n",
    "          os.path.join(model_path, 'bert_base_uncased_107th_congress')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The workhorse function here is computePerplexitiesForPrescience\n",
    "\n",
    "View it's docstring. For illustrative purposes we'll be setting compute_sent_perp to false. This returns word-level perplexities instead of sentence-level perplexities - useful for exploring _what_ words contribute to prescience but is significantly more memory intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computePerplexitiesForPrescience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_87 = computePerplexitiesForPrescience(cong_87, 'speech', model_names=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
